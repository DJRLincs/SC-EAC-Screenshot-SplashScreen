"use strict";
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.download = exports.verifyDownloadedChunk = void 0;
/* eslint-disable no-param-reassign */
const promises_1 = require("timers/promises");
const promise_pool_1 = __importDefault(require("@supercharge/promise-pool"));
const stream_throttle_1 = require("stream-throttle");
const constants_1 = require("./constants");
const errors_1 = require("./errors");
const hashStream_1 = require("./hashStream");
const mdFileInfo_1 = require("./mdFileInfo");
const types_1 = require("./types");
const aggregateDownloadStatisticsReport_1 = require("../aggregateDownloadStatisticsReport");
const downloadStatisticsStream_1 = __importDefault(require("../downloadStatisticsStream"));
const Local = __importStar(require("../local"));
const rangeWritableStream_1 = __importDefault(require("../rangeWritableStream"));
const Remote = __importStar(require("../remote"));
/**
 * Verify the downloaded chunk against the hash in the verification header
 *
 * @param file - MDFile instance
 * @param chunk - Chunk to verify
 * @returns - MDFile instance
 * @example - verifyDownloadedChunk(file, chunk) // => MDFile instance
 */
async function verifyDownloadedChunk(file, chunk) {
    const { header: { verificationHeader }, } = file;
    if (!verificationHeader) {
        return file;
    }
    chunk.status = types_1.ChunkStatus.Verifying;
    const { chunks: { algorithm, hashes }, } = verificationHeader;
    const chunkHash = hashes[chunk.id];
    const readStream = Local.createReadStreamFromRange([chunk.range[0], chunk.range[1]])(file.fileHandle);
    const hash = await (0, hashStream_1.hashStream)(algorithm)(readStream);
    if (hash !== chunkHash) {
        throw new errors_1.HashMismatchError(`Chunk ${chunk.id} (${chunk.range[0]}-${chunk.range[1]}) => Expected: ${chunkHash} <-> Actual: ${hash}`);
    }
    return file;
}
exports.verifyDownloadedChunk = verifyDownloadedChunk;
/**
 * Download a chunk of a file and write it to disk
 *
 * @param file - MDFile instance
 * @param aggStream - AggregatedDownloadStatisticsReportStream instance
 * @param chunk - Chunk to download
 * @param currentRetry - Current retry count
 * @param rateLimit - Rate limit in bytes per second
 * @returns - MDFile instance and a stop function
 * @example - doDownloadChunk(file, aggStream, chunk, currentRetry, rateLimit) // => { file: MDFile, stop: () => void }
 */
async function doDownloadChunk(file, aggStream, chunk, currentRetry, rateLimit, concurrentDownloads, signal) {
    const startPosition = chunk.range[0] + chunk.downloaded;
    const readyToVerify = startPosition === chunk.range[1] + 1;
    if (readyToVerify) {
        return { file, stop: () => aggStream.stop() };
    }
    try {
        const remoteStream = await Remote.retrieveContentRange(new URL(file.header.url), [startPosition, chunk.range[1]]);
        const rangeWritableStream = new rangeWritableStream_1.default({
            fileHandle: file.fileHandle,
            rangeStartPosition: startPosition,
        });
        const downloadStatisticsStream = new downloadStatisticsStream_1.default({
            alreadyDownloaded: chunk.downloaded,
            fileSize: chunk.size - chunk.downloaded,
            key: chunk,
        });
        return await new Promise((resolve, reject) => {
            rangeWritableStream.on('error', reject);
            rangeWritableStream.on('finish', async () => {
                chunk.downloaded = chunk.size;
                try {
                    await verifyDownloadedChunk(file, chunk);
                    chunk.status = types_1.ChunkStatus.Completed;
                    resolve({ file, stop: () => aggStream.stop() });
                }
                catch (error) {
                    reject(error);
                }
            });
            rangeWritableStream.on('data-written', (downloaded) => {
                chunk.downloaded = downloaded;
            });
            remoteStream.on('data', () => {
                if (signal.aborted) {
                    remoteStream.destroy();
                    reject();
                }
            });
            downloadStatisticsStream.reporter.on('data', (c) => {
                aggStream.write(c, (error) => {
                    if (error) {
                        downloadStatisticsStream.reporter.emit('error', error);
                    }
                });
            });
            if (rateLimit) {
                remoteStream
                    .pipe(new stream_throttle_1.Throttle({
                    rate: Math.floor(rateLimit / concurrentDownloads),
                }))
                    .pipe(downloadStatisticsStream)
                    .pipe(rangeWritableStream);
            }
            else {
                remoteStream.pipe(downloadStatisticsStream).pipe(rangeWritableStream);
            }
        });
    }
    catch (error) {
        if (error instanceof errors_1.HashMismatchError && currentRetry > 0) {
            chunk.downloaded = 0;
            return (0, promises_1.setTimeout)(500, doDownloadChunk(file, aggStream, chunk, currentRetry - 1, rateLimit, concurrentDownloads, signal));
        }
        throw error;
    }
}
/**
 * Download a chunk of a file
 * @param file - MDFile instance
 * @param stream - AggregatedDownloadStatisticsReportStream instance
 * @param rateLimit - Rate limit in bytes per second
 * @returns - returns a MDFile instance or a MDFile instance and a stop function if the chunk is already downloaded
 */
async function downloadChunk(file, stream, chunk, rateLimit, concurrentDownloads, signal) {
    if (chunk.status === types_1.ChunkStatus.Completed) {
        return file;
    }
    chunk.status = types_1.ChunkStatus.Downloading;
    const downloadedFile = (await Promise.race([
        doDownloadChunk(file, stream, chunk, file.header.retries, rateLimit, concurrentDownloads, signal),
        new Promise((_, reject) => {
            signal.addEventListener('abort', () => reject(new Error('Download cancelled')));
        }),
    ]));
    if (signal.aborted) {
        return null;
    }
    return downloadedFile;
}
/**
 * Download a file from a remote server and write it to disk in chunks of a given size
 *
 * @param file - MDFile instance
 * @param progressCallback - Callback function to receive download progress
 * @param options - Options object // => { rateLimit: number }
 * @returns - MDFile instance
 * @example - download(file, progressCallback, { rateLimit: 1000000 }) // => MDFile instance
 */
function download(file, progressCallback, options = {}) {
    const controller = new AbortController();
    const alreadyDownloaded = file.chunks.reduce((acc, chunk) => acc + chunk.downloaded, 0);
    const aggregatedDownloadStream = new aggregateDownloadStatisticsReport_1.AggregatedDownloadStatisticsReportStream({
        fileSize: file.header.size,
        alreadyDownloaded,
    });
    progressCallback(aggregatedDownloadStream);
    const actualRateLimit = options.rateLimit ?? constants_1.DEFAULT_RATE_LIMIT;
    const actualconcurrentDownloads = options.concurrentDownloads ?? constants_1.DEFAULT_CONCURRENT_DOWNLOADS;
    const headerUpdater = async (signal) => {
        while (!file.finished) {
            try {
                await (0, promises_1.setTimeout)(2000, { signal });
                await (0, mdFileInfo_1.writeMDFileInfo)(file.fileHandle, { header: file.header, chunks: file.chunks }, file.header.size);
            }
            catch (error) {
                if (error instanceof Error && error.name === 'AbortError') {
                    return;
                }
                throw error;
            }
        }
    };
    const chunksDownload = async () => {
        const { errors } = await promise_pool_1.default.for(file.chunks)
            .withConcurrency(actualconcurrentDownloads)
            .process(async (chunk, _, pool) => {
            if (controller.signal.aborted) {
                pool.stop();
                return;
            }
            await downloadChunk(file, aggregatedDownloadStream, chunk, actualRateLimit, actualconcurrentDownloads, controller.signal);
        });
        if (controller.signal.aborted) {
            return file;
        }
        if (errors.length > 0) {
            throw new errors_1.InvalidMDFileError('MDFile chunks corrupted', { cause: 'chunks corrupted' });
        }
        await (0, mdFileInfo_1.writeMDFileInfo)(file.fileHandle, { header: file.header, chunks: file.chunks }, file.header.size);
        aggregatedDownloadStream.stop();
        file.finished = true;
        return file;
    };
    const downloadPromise = Promise.race([chunksDownload(), headerUpdater(controller.signal)]).then(() => {
        aggregatedDownloadStream.stop();
        return file;
    });
    const cancelDownload = () => {
        controller.abort();
    };
    return [downloadPromise, cancelDownload, controller.signal];
}
exports.download = download;
//# sourceMappingURL=download.js.map